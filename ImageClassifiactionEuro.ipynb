{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageClassifiactionEuro.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNd1QMCHkmLyT5zSz1bZNfL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mihaelakri/ShoppingEyes/blob/master/ImageClassifiactionEuro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Euro classification with TensorFlow\n",
        "\n",
        "It is very important to make a very good model to classify images in this case for euro banknotes. How we can solve this issue?\n",
        "\n",
        "The [TensorFlow](https://www.tensorflow.org/lite/guide/model_maker) model maker library can be a excellent tool to solve that issue.\n",
        "\n",
        "For image classification we need resources aka. images so we need computing power to analyze the pictures. To tackle that Google Colab offers Hosted Runtime from the Google Cloud for free."
      ],
      "metadata": {
        "id": "4BJd-AetOIZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies\n",
        "\n",
        "The crucial part of the model maker program to use and install our dependencies.\n",
        "<br>\n",
        "If you try to run this script on premise make sure you use pip and download and install these dependencies."
      ],
      "metadata": {
        "id": "9fDI-T7sQiFR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zc-fx4SiMFZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e19329-d3be-47b3-e468-938f4b5c1509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 616 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 234 kB 52.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 40.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 45.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 840 kB 49.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 46.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 40.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 52.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 24.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 7.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 46.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.7 MB 67 kB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 62.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 211 kB 47.7 MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tflite-model-maker\n",
        "!pip install -q matplotlib\n",
        "!pip install -q numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the dependencies\n",
        "\n",
        "After the installation of the dependencies make sure you imported all the important functions and components that could be useful to make our model."
      ],
      "metadata": {
        "id": "Itd_rLPBD33h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.image_classifier import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "BHbl2eoBM_qe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you run this script on premise it can be useful to use local directory and not downloading the tgz archive from the internet.\n",
        "\n",
        "To demonstrate the model maker I used a tar file which downloaded from a webserver \n",
        "\n",
        "You can't just throw the pictures and the program determines what you did we used directories to sort all the types of classes that we would like to identify\n",
        "<br>\n",
        "<br>\n",
        "![image](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "EDPIyenyERws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.list_physical_devices('GPU')\n",
        "# image_path = \"Your local path\"\n",
        "image_path = tf.keras.utils.get_file('Euro','https://web.unideb.hu/zsolt.berecz/ShoppingEyes/Euro.tgz',untar=True) # Remember the first input is the folder name which contains the \"labels\" aka sub folders\n",
        "data = DataLoader.from_folder(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgUh6eDyNAuA",
        "outputId": "90119a09-afb4-4bb9-c0ca-1f93e7581308"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://web.unideb.hu/zsolt.berecz/ShoppingEyes/Euro.tgz\n",
            "5931229184/5931225263 [==============================] - 232s 0us/step\n",
            "5931237376/5931225263 [==============================] - 232s 0us/step\n",
            "INFO:tensorflow:Load image with size: 2118, num_label: 7, labels: 10, 100, 20, 200, 5, 50, 500.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, I downloaded the pictures then what?\n",
        "\n",
        "The next step is to train our model with the data(images) that was downloaded.\n",
        "\n",
        "I used the default options but it can be changed for instance the algorithm method or the batch size,epoch.\n"
      ],
      "metadata": {
        "id": "UbAcLj7TFOqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, rest_data = data.split(0.8) # 80% training data 10 % for test and 10% for validation\n",
        "#train_data, test_data = data.split(0.9)\n",
        "validation_data, test_data = rest_data.split(0.5)\n",
        "\n",
        "model = image_classifier.create(train_data)\n",
        "#model = image_classifier.create(train_data, validation_data=validation_data,model_spec=model_spec.get('efficientnet_lite4'),epochs = 10,batch_size = 16) #resnet_50 default epochs = 50 and batch_size = 16\n",
        "print(\"Evaluate the result of the model, get the loss and accuracy of the model:\\n\")\n",
        "loss, accuracy = model.evaluate(test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fdOV1INNeAy",
        "outputId": "75665534-7b70-43ce-d2cd-33284894e620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Retraining the models...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hub_keras_layer_v1v2 (HubKe  (None, 1280)             3413024   \n",
            " rasLayerV1V2)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 7)                 8967      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,421,991\n",
            "Trainable params: 8,967\n",
            "Non-trainable params: 3,413,024\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/52 [============================>.] - ETA: 12s - loss: 1.0266 - accuracy: 0.7837"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And that's it!\n",
        "\n",
        "\n",
        "Congratulations you can make models which classify pictures, in this case banknotes.\n",
        "\n",
        "When the train finished the Python script exports the **.tflite** file to the directory where you started running the script."
      ],
      "metadata": {
        "id": "Qbecq0wTHQyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate_tflite('model.tflite', test_data)\n",
        "model.export(export_dir='.')\n",
        "\n",
        "#Download from the Google Colab:\n",
        "files.download('model.tflite') \n",
        "# just the label\n",
        "# model.export(export_dir='.', export_format=ExportFormat.LABEL)"
      ],
      "metadata": {
        "id": "YmI02AsANmGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model"
      ],
      "metadata": {
        "id": "kJZx9m1EINqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_color(val1, val2):\n",
        "    if val1 == val2:\n",
        "        return 'black'\n",
        "    else:\n",
        "        return 'red'\n",
        "\n",
        "def test_model():\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    predicts = model.predict_top_k(test_data)\n",
        "    for i, (image, label) in enumerate(test_data.gen_dataset().unbatch().take(100)):\n",
        "        ax = plt.subplot(10, 10, i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
        "\n",
        "        predict_label = predicts[i][0][0]\n",
        "        color = get_label_color(predict_label,test_data.index_to_label[label.numpy()])\n",
        "        ax.xaxis.label.set_color(color)\n",
        "        plt.xlabel('Predicted: %s' % predict_label)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "test_model()"
      ],
      "metadata": {
        "id": "qyMpDgqDN7UO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}